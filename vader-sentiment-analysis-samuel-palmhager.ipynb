{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9538515,"sourceType":"datasetVersion","datasetId":5782610}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Sentiment analysis**\n\nHello and welcome to my sentiment analysis project. This will be conducted on a spotify reviews dataset that contain reviews about the application. The csv-file is split into two columns, the first contains a review and the second column contains a label about the general sentiment of the review.\n\nThe sentiment analysis practice we will be applying in this project is the NLTKS VADER teqnique.\n\nSentiment analysis is a powerful data analysation tool that enables insight into the sentiment of a text. The two first essential steps of the process is the following for VADER: \n\n    1. Tokenizing the string. The process of breaking up each review into the words that make it up and populating a list.\n    2. Part of speech. The process of labeling each token with it's corresponding grammatical category. \n","metadata":{}},{"cell_type":"markdown","source":"**Import neccesary libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T22:31:19.995059Z","iopub.execute_input":"2024-11-27T22:31:19.995430Z","iopub.status.idle":"2024-11-27T22:31:22.042593Z","shell.execute_reply.started":"2024-11-27T22:31:19.995384Z","shell.execute_reply":"2024-11-27T22:31:22.041505Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/spotify-dataset/DATASET.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:11:31.864240Z","iopub.execute_input":"2024-11-14T15:11:31.864896Z","iopub.status.idle":"2024-11-14T15:11:32.206101Z","shell.execute_reply.started":"2024-11-14T15:11:31.864847Z","shell.execute_reply":"2024-11-14T15:11:32.205006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Lets first explore the dataset! We want to get an overview of the proportion of positive/negative reviews and also explore some example reviews.\n\nGiven that our label column contains categorial values we first need to perform a get_dummies operation. This  creates two new columns with boolean values that is true/false if the value is present in the row. This allows us to aggregate it in a piechart.","metadata":{}},{"cell_type":"code","source":"dummy_df = pd.get_dummies(df['label'])\ndummy_df.head()\n\nPositive, Negative = dummy_df['POSITIVE'].sum(), dummy_df['NEGATIVE'].sum()\ndata, labels = [Positive, Negative], [\"Positive\", \"Negative\"] \n\nfig, ax = plt.pie(data, labels = labels, startangle = 140)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:11:34.139056Z","iopub.execute_input":"2024-11-14T15:11:34.139536Z","iopub.status.idle":"2024-11-14T15:11:34.345672Z","shell.execute_reply.started":"2024-11-14T15:11:34.139490Z","shell.execute_reply":"2024-11-14T15:11:34.343197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"randomInt = random.randint(0,500)\nexample = df['Review'][randomInt]\nprint(f\"The review number: {randomInt}\", example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:48:14.146947Z","iopub.execute_input":"2024-11-14T15:48:14.147484Z","iopub.status.idle":"2024-11-14T15:48:14.159132Z","shell.execute_reply.started":"2024-11-14T15:48:14.147428Z","shell.execute_reply":"2024-11-14T15:48:14.157542Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Lets do some tokenization, first we need to download the nltk data for tokenization. Then we will perform a tokenization on an example review.","metadata":{}},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:11:42.734659Z","iopub.execute_input":"2024-11-14T15:11:42.735105Z","iopub.status.idle":"2024-11-14T15:12:02.787759Z","shell.execute_reply.started":"2024-11-14T15:11:42.735063Z","shell.execute_reply":"2024-11-14T15:12:02.786468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example_tokenized = word_tokenize(example)\nexample_tokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:48:19.673889Z","iopub.execute_input":"2024-11-14T15:48:19.674471Z","iopub.status.idle":"2024-11-14T15:48:19.687006Z","shell.execute_reply.started":"2024-11-14T15:48:19.674417Z","shell.execute_reply":"2024-11-14T15:48:19.684192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we need to apply part of speech on the tokenized review. This ensures that words are put in their correct grammatical category by labeling them with a two letter code. This is an important step seeing that the english language has many words that can be used in different grammatical context. For example the word 'run' can, depending on the context, be a:\n\n    1. Verb - I run every morning\n    2. Adjective - We did a test run of the system yesterday.\n\nAfter this we will chunk it to a chunk object. What this does is grouping together the tokenized review, that has been tagged by POS, into a chunk of words so it actually forms a sentance.","metadata":{}},{"cell_type":"code","source":"pos_example = nltk.pos_tag(example_tokenized)\npos_example\npos_example_chunk = nltk.chunk.ne_chunk(pos_example)\npos_example_chunk.pprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:48:22.203655Z","iopub.execute_input":"2024-11-14T15:48:22.204175Z","iopub.status.idle":"2024-11-14T15:48:22.234491Z","shell.execute_reply.started":"2024-11-14T15:48:22.204129Z","shell.execute_reply":"2024-11-14T15:48:22.231941Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now have done the necessary steps to prime the data for our VADER sentiment analysis. This is a rule based sentiment analysis approach which is fitting for shorter and more informal texts, such as tweets and/or reviews. It is fitting for this because it works very well when the writer expresses their sentiment with slang, emoticons and exaggerated words. \n\nIt is a very lightweight approach to sentiment analysis seeing that it makes work of a bag-of-words (BoW) apporach rather than training a model to evaluate the sentiment of a text. BoW utilizes a dictionary of 7500 manually labeled words with a 'valence score', this represents on a scale from 0-1 how negative, neutral or positive a review is. It manually assigns each token in the string a score and then aggregates the scores to form a numerical summarization that we can interpit. \n\nThe shortcommings in VADER lies in it's inabillity to handle text that is more nuanced, especially when it comes to sarcasm. Seeing that the words of a sarcastic review can come of as objectively positive the VADER might interpit it as this, when it is obivously sarcastic. For example:\n\n*Wow, this product is truly amazing. I mean, who doesn't love waiting for hours only to find out it doesn’t work at all? The best part? It breaks after one use, so I don’t even have to worry about storage space! Five stars for creativity on how badly designed this is.*\n\nSome words that can seriously throw of the VADER is:\n\n    1. Amazing \n    2. Best part\n    3. Five stars\n\nOnce run through a VADER model it will get a positive score, even tough the customer was unhappy with the product. \n\nThis aside, we can continue implementing VADER. ","metadata":{}},{"cell_type":"code","source":"nltk.download('vader_lexicon')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:34:21.159467Z","iopub.execute_input":"2024-11-14T15:34:21.160456Z","iopub.status.idle":"2024-11-14T15:34:41.203891Z","shell.execute_reply.started":"2024-11-14T15:34:21.160388Z","shell.execute_reply":"2024-11-14T15:34:41.202816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sia = SentimentIntensityAnalyzer()\nsia.polarity_scores(example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T15:48:34.904295Z","iopub.execute_input":"2024-11-14T15:48:34.904994Z","iopub.status.idle":"2024-11-14T15:48:34.935631Z","shell.execute_reply.started":"2024-11-14T15:48:34.904929Z","shell.execute_reply":"2024-11-14T15:48:34.932342Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cool it works! Let's do this on the first 1000 rows of our spotify dataframe, store it in a temporary dictionary and then merge it to our sliced dataframe. We put it into a dataframe for easy merging with the dataframe.","metadata":{}},{"cell_type":"code","source":"df_1000 = df[:1000].reset_index(drop=True)\ndf_1000['Id'] = df_1000.index\ndict = {}\ndf_1000.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T16:33:11.472840Z","iopub.execute_input":"2024-11-14T16:33:11.473293Z","iopub.status.idle":"2024-11-14T16:33:11.487782Z","shell.execute_reply.started":"2024-11-14T16:33:11.473245Z","shell.execute_reply":"2024-11-14T16:33:11.486441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, row in df_1000.iterrows():\n    text = row['Review']\n    rowId = row['Id']\n    dict[rowId] = sia.polarity_scores(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T16:36:37.470013Z","iopub.execute_input":"2024-11-14T16:36:37.470473Z","iopub.status.idle":"2024-11-14T16:36:38.101211Z","shell.execute_reply.started":"2024-11-14T16:36:37.470427Z","shell.execute_reply":"2024-11-14T16:36:38.100222Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's merge it with the dataframe! In order to do this we need to convert the dictionary to a dataframe and ensure that there is a common column that the dataframes can be merged on. We will use the ID column we created above for this.","metadata":{}},{"cell_type":"code","source":"vaders_df = pd.DataFrame(dict).T\nvaders_df['Id'] = vaders_df.index\nvaders_df = vaders_df.merge(df_1000, on = 'Id', how = 'right')\nvaders_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T16:48:05.138077Z","iopub.execute_input":"2024-11-14T16:48:05.138583Z","iopub.status.idle":"2024-11-14T16:48:05.197951Z","shell.execute_reply.started":"2024-11-14T16:48:05.138537Z","shell.execute_reply":"2024-11-14T16:48:05.196592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cool! We have attatched the compound values of the VADER model to each review! Let's do some exploratory data analysis on this new dataframe. Let's see do histogram displaying the distribution of the compounded VADER scores.\n\nWe will show a histogram, displaying the distribution of the compound scores. Also a scatterplot which shows us the relationship between the length of a review and the associated compound score. ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n\nsns.histplot(vaders_df['compound'], kde = True, bins = 10, ax=ax[0])\nax[0].set_title('Distribution of VADER Compound Scores')\nax[0].set_xlabel('Compound Score')\nax[0].set_ylabel('Frequency')\n\nvaders_df['Review_length'] = vaders_df['Review'].apply(len)\nsns.scatterplot(x = \"compound\", y = \"Review_length\", data=vaders_df,ax=ax[1])\nax[1].set_title('Review Length vs VADER Sentiment Score')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T17:13:57.500215Z","iopub.execute_input":"2024-11-14T17:13:57.501005Z","iopub.status.idle":"2024-11-14T17:13:58.325469Z","shell.execute_reply.started":"2024-11-14T17:13:57.500942Z","shell.execute_reply":"2024-11-14T17:13:58.324049Z"}},"outputs":[],"execution_count":null}]}